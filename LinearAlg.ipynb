{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72acbd94-93c6-4dd3-8984-78ff1547c5ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sources\n",
    "\n",
    "- [Gilbert Strang’s Class - MIT Linear Algebra Fall 2011](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/resource-index/)\n",
    " - Uses Introduction to Linear Algebra, 5th Edition\n",
    "- [3 blue 1 brown vids - Essence of Linear Algebra](https://www.youtube.com/watch?v=LyGKycYT2v0&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=10)\n",
    "- May test myself on [Khan](https://www.khanacademy.org/math/linear-algebra) but not planning to use his videos between the textbook and the above vids\n",
    "- Going to distribute [Numpy](https://numpy.org/doc/stable/user/absolute_beginners.html) stuff as I go.  Taking notes separately on that.\n",
    "\n",
    "# Introduction to Vectors\n",
    "\n",
    "[Take notes on the different Forms being equivalent that he discusses in his lecture https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/resource-index/#?w=535]\n",
    "\n",
    "Vectors are **independent** if no combination other than 0 multiples gives `b=0`.  Vectors are **dependent** if multiple combinations give `b=0`.\n",
    "\n",
    "## Lengths and Dot Products\n",
    "Dot product relates to how you can split matrix into combos. Strang said you can think of matrix multiplication as combination of columns.\n",
    "\n",
    "The length $||v||$ of a vector is $\\sqrt(v \\cdot v)$.\n",
    "\n",
    "When you multiply two vectors and the dot product is zero, they are perpindicular.  More generally, the angle $\\theta$ between vectors $v$ and $w$ has:\n",
    "$$\n",
    "\\frac{\\cos(v \\cdot w)}{||v||\\;||w||}\n",
    "$$\n",
    "\n",
    "[I would like a better geometric understanding of this ^]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Matrices\n",
    "\n",
    "#### Matrix Multiplication\n",
    "\n",
    "See https://www.mathsisfun.com/algebra/matrix-multiplying.html, specifically https://www.mathsisfun.com/algebra/images/matrix-multiply-a.svg\n",
    "It works through the dot product of each row and column.\n",
    "\n",
    "In order to multiply two matrices, the number of columns of A must equal the number of rows of B. The product\n",
    "AB will have the same number of rows as the first matrix and the same number of columns as the second.\n",
    "\n",
    "A matrix is **invertible** if it has independent (see definition above) column vectors, meaning `Ax = 0` has only one solution.\n",
    "\n",
    "A matrix is **singular** if `Ax=0` has many solutions.\n",
    "\n",
    "\n",
    "\n",
    "3Blue1Brown emphasized:\n",
    "- Viewing Matrices as transformation of space\n",
    "- Matrix multiplication is just one transformation affer another [this may belong in subsequent section]\n",
    "\n",
    "# Solving Linear Equations\n",
    "## Vectors and Linear Equations\n",
    "## The Idea of Elimination \n",
    "## Elimination Using Matrices \n",
    "## Rules for Matrix Operations\n",
    "## Inverse Matrices \n",
    "## Elimination = Factorization: A = LU\n",
    "## Transposes and Permutations\n",
    "# Vector Spaces and Subspaces\n",
    "## Spaces of Vectors\n",
    "## The Nullspace of A: Solving Ax = 0 and Rx = 0 \n",
    "## The Complete Solution to Ax = b\n",
    "## Independence, Basis and Dimension\n",
    "## Dimensions of the Four Subspaces\n",
    "# Orthogonality \n",
    "## Orthogonality of the Four Subspaces \n",
    "## Projections \n",
    "## Least Squares Approximations \n",
    "## Orthonormal Bases and Gram-Schmidt \n",
    "# Determinants 247\n",
    "## The Properties of Determinants \n",
    "## Permutations and Cofactors \n",
    "## Cramer’s Rule, Inverses, and Volumes \n",
    "# Eigenvalues and Eigenvectors 288\n",
    "## Introduction to Eigenvalues \n",
    "## Diagonalizing a Matrix \n",
    "## Systems of Differential Equations \n",
    "## Symmetric Matrices \n",
    "## Positive Definite Matrices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757eb249-dda3-4358-92c6-3fea39573519",
   "metadata": {},
   "source": [
    "# Vectors from Calc\n",
    "\n",
    "[MAKES SENSE to integrate this in line with below sections from Linear Alg]\n",
    "\n",
    "Using [Khan](https://www.khanacademy.org/math/get-ready-for-ap-calc/xa350bf684c056c5c:get-ready-for-parametric-polar-vector) to get the basics here just as part of doing AP Calc.  But will expand this once taking on Linear Algebra.\n",
    "\n",
    "A **Vector** has a **magnitude/size** and a **direction/angle**.  A **Scalar** only has the former.\n",
    "\n",
    "A vector is not defined by it's starting point, just its magnitude and direction.  It could be dropped anywhere on a graph.\n",
    "\n",
    "Vectors can be split up into Parametric Equations.  [0 upvote MSE Question](https://math.stackexchange.com/a/1940372/49487) which hopefully is correct:\n",
    "\n",
    "> parametric equation with only one parameter, it's the same thing. The parametric equations are the components of the vector function.\n",
    "\n",
    "[Euclidean Vectors](https://en.wikipedia.org/wiki/Euclidean_vector) are all I dealt with in Calc.  When taking on Linear, will move beyond these. [Position Vectors](https://en.wikipedia.org/wiki/Position_(geometry)) are Euclidean Vectors that start at the origin at point to something in Euclidean space.\n",
    "\n",
    "[Vector Space](https://en.wikipedia.org/wiki/Vector_space)\n",
    "[Write formal definition of vector (Spaces) as part of linear alg]\n",
    "\n",
    "## Norm / Magnitude\n",
    "\n",
    "Vector magnitude from components:\n",
    "The magnitude of $(a, b)$ is $\\|(a, b)\\|=\\sqrt{a^{2}+b^{2}}$.\n",
    "\n",
    "## Direction of Vectors\n",
    "\n",
    "Arctan has a limited range, so if you want to get an angle from the vector components. In Quadrants II and III, you'll wanna add 180.  In Quadrant IV, you'll get a negative angle which you can add 360 to to get a positive one.  \n",
    "\n",
    "If you're using [atan2](https://en.wikipedia.org/wiki/Atan2), it works a bit different than that.\n",
    "\n",
    "## Vector components from magnitude and direction\n",
    "\n",
    "The components of a vector with magnitude $\\|\\vec{u}\\|$ and direction $\\theta$ are $(\\|\\vec{u}\\| \\cos (\\theta),\\|\\vec{u}\\| \\sin (\\theta))$.\n",
    "\n",
    "## Unit Vectors\n",
    "[Unit vector](https://en.wikipedia.org/wiki/Unit_vector) is a vector of length 1.\n",
    "\n",
    "[Notation varies](https://math.stackexchange.com/questions/965477/unit-vector-symbols-names) for them, but Khan seems to prefer $\\hat i, \\hat j$.\n",
    "\n",
    "## Multiplying and Dividing Vectors\n",
    "\n",
    "**Scalar Multiplication** is scalar times a vector.  Pretty straightforward since it just multiplies the components.\n",
    "\n",
    "## Vector valued functions\n",
    "\n",
    "Typical notation for a **Vector Function** aka **Vector Valued Function** is either arrow over like $\\vec{v}$  (I prefer, cus I write it same with pencil) or else bold it.\n",
    "\n",
    "$\\vec{r}(t) = x(t)\\hat i + y(t)\\hat j$\n",
    "\n",
    "From this definition, and the limit definition of a derivative, we see that we can get the derivative of vector functions.\n",
    "\n",
    "### Vector Valued Function Differentiation\n",
    "\n",
    "The derivative of a vector is itself a vector.\n",
    "\n",
    "$\\vec{r}'(t) = x'(t)\\hat i + y'(t)\\hat j$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
