{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bsgreenb/math-tools/blob/master/DiffCalc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90uOwIG4e31U"
   },
   "source": [
    "# Limits\n",
    "\n",
    "Limit exists if limits from both sides exist:\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to{a}}f(x) \\text{ exists if} \\lim_{x\\to{a^-}}f(x) = \\lim_{x\\to{a^+}}f(x) \n",
    "$$\n",
    "\n",
    "$0/0$ is _indeterminate_ meaning infinite solutions. Indeterminate may turn out to be tractable, undefined cannot be.\n",
    "\n",
    "Keep in mind that when you rearrange a limit equation, you don't remove the discontinuity at the point when you remove the 0 denominator through cancelling out.. It's still undefined at that point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT5YfEB7kqe7"
   },
   "source": [
    "\n",
    "## Epsilon Delta Definition of a Limit\n",
    "Suppose that we have a function\n",
    "$ f: \\mathbb{R} \\rightarrow \\mathbb{R} $, and c, L $\\in \\mathbb{R}$.  Then the limit \n",
    "$$ \\lim_{x\\to c}f(x) = L $$ \n",
    "\n",
    "means for any real $\\epsilon > 0$, there exists a $\\delta > 0$ such that for any real $x$, $0 < |x - c|< \\delta$ implies $|f(x) - L|<\\epsilon$. Or in pure logic:\n",
    "\n",
    "$$\n",
    "\\forall \\epsilon \\in \\mathbb{R} > 0 ~\\exists \\delta \\in \\mathbb{R} > 0[\\forall x \\in \\mathbb{R} ~0 < |x-c| < \\delta \\rightarrow |f(x) - L| < \\epsilon]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAlZiX9Bkqe7"
   },
   "source": [
    "### Epsilon Delta Definition of One-Sided Limits\n",
    "The limit from the left,\n",
    "$$\n",
    "\\lim_{x\\to{c^-}}f(x) = L\n",
    "$$\n",
    "means for any real $\\epsilon > 0$, there exists a $\\delta > 0$ such that for any real $x$, $0 < (c - x)< \\delta$ implies $|f(x) - L|< \\epsilon$.\n",
    "\n",
    "The limit from the right,\n",
    "$$\n",
    "\\lim_{x\\to{c^+}}f(x) = L\n",
    "$$\n",
    "means for any real $\\epsilon > 0$, there exists a $\\delta > 0$ such that for any real $x$, $ 0 < (x - c)< \\delta$ implies $|f(x) - L|< \\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggeCsGzqkqe8"
   },
   "source": [
    "## Limit Properties\n",
    "\n",
    "Assume $\\lim \\limits_{x \\to a} f(x) = K$ and $\\lim \\limits_{x \\to a} f( x ) = L$.\n",
    "\n",
    "**Constant Function Property**: \n",
    "\n",
    "$$ \\lim_{x\\to a}[c] = c $$\n",
    "\n",
    "**Constant Multiple Property**:\n",
    "\n",
    "$$ \\lim_{x\\to a}[cf(x)] = c\\lim_{x\\to a}f(x) =cK $$\n",
    "\n",
    "**Limit Sum Property**:\n",
    "\n",
    "$$ \\lim_{x\\to a}[f(x) + g(x)] = \\lim_{x\\to a}f(x) + \\lim_{x\\to a}g(x) = K + L $$\n",
    "\n",
    "**Limit Product Property**:\n",
    "\n",
    "$$ \\lim_{x\\to a}[f(x)\\cdot g(x)] = \\lim_{x\\to a}f(x) \\cdot \\lim_{x\\to a}g(x) = KL $$\n",
    "\n",
    "**Limit Quotient Property**:\n",
    "\n",
    "$$ \\lim_{x\\to a}\\frac{f(x)}{g(x)} = \\frac{\\lim\\limits_{x\\to a}f(x)}{\\lim\\limits_{x\\to a}g(x)} = \\frac{K}{L} \\quad\\text {provided $L=\\lim\\limits_{x\\to a}g(x) \\neq 0$} $$\n",
    "\n",
    "**Limit Exponent Property**:\n",
    "\n",
    "$$ \\lim_{x\\to a}[f(x)]^n = [\\lim_{x\\to a}f(x)]^n = K^n \\quad\\text{where $n \\in \\mathbb{R}$}$$ \n",
    "\n",
    "^^ Basically all of these properties act in the way we'd naturally want/expect.\n",
    "\n",
    "In my notebooks, I proved these with epsilon delta using [this resource](https://tutorial.math.lamar.edu/classes/calci/limitproofs.aspx) as a guide.  Note that it only proves the exponent property is only proven for natural numbers.\n",
    "\n",
    "Note that a composite limit might exist even if its constituents don't after applying properties above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmiyBNutkqe-"
   },
   "source": [
    "## Limit of Composite function\n",
    "If $ \\lim_{x\\to a}g(x) $ exists and $f$ is continuous at $g$\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to a} f(g(x)) = f(\\lim_{x\\to a}g(x))\n",
    "$$\n",
    "\n",
    "Make sure to check those conditions are met.\n",
    "\n",
    "Finally wrapped by head around the proof with this https://youtu.be/xH5PlQRzLmw . You replace one of the epsilons with the delta from the other, so you setup a chain of logical implication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLai7qNXkqe-"
   },
   "source": [
    "\n",
    "## Strategy for Limits\n",
    "- Solve at the point f(x) if you can\n",
    "- Only continue if it's indeterminate.  If it's b/0 and b isn't 0, proly not worth continuing.\n",
    "- Solve indeterminate with either factoring, or multiplying by conjugate, or by trig substitution.\n",
    "\n",
    "Using trig idenitties can allow you to express multiple parts as something simpler, e.g. using Pythagorean Trig limit you can get $\\cos^2$ or $\\sin^2$ in terms of each other.  Basically the strategy here as elsewhere in algebra is to generate cancellable (which often, but not always means similar) terms.\n",
    "\n",
    "There's more complex strategy to follows, as we haven't dealt with some special values yet, or even broached differentiation.  Will likely update this section later.\n",
    "\n",
    "This summarizes this basic view: https://www.youtube.com/watch?v=ZaLw1cunN3s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mamXnJRkqe_"
   },
   "source": [
    "\n",
    "## The Squeeze Theorem\n",
    "Aka the Sandwich Theorem.\n",
    "\n",
    "**Squeeze Theorem**: Suppose that $$ f(x) \\leq g(x) \\leq h(x)$$ for all $x$ in some interval around $c$, with the possible exclusion of $c$ itself. Also suppose that $$ \\lim_{x\\to c} f(x) = L = \\lim_{x\\to c} h(x). $$ Then $$\\lim_{x\\to c} g(x) = L.$$\n",
    "\n",
    "_Proof_: We want to prove $\\lim\\limits_{x\\to c} g(x) = L$ given the premises above it.  Let $\\epsilon$ be any real number more than $0$, and let $x$ be any real number.  By the definition of a limit,\n",
    "\n",
    "$$ \\lim_{x\\to c}f(x) = L$$\n",
    "\n",
    "means there exists a a $\\delta_f$ such that,\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "0 < |x-c| < \\delta_f &\\rightarrow |f(x) - L| < \\epsilon  \\\\\n",
    "0 < |x-c| < \\delta_f &\\rightarrow -\\epsilon < f(x) - L < \\epsilon. \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And \n",
    "\n",
    "$$ \\lim_{x\\to c}h(x) = L$$\n",
    "\n",
    "means there exists a a $\\delta_h$ such that,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "0 < |x-c| < \\delta_h &\\rightarrow |h(x) - L| < \\epsilon \\\\\n",
    "0 < |x-c| < \\delta_h &\\rightarrow -\\epsilon < h(x) - L < \\epsilon. \\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The open interval around $c$, with the possible exclusion of $c$ itself, can be described with some $\\delta_g$, such that\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "0 < |x-c| < \\delta_g &\\rightarrow f(x) \\leq g(x) \\leq h(x) \\\\\n",
    "0 < |x-c| < \\delta_g &\\rightarrow f(x) - L \\leq g(x) - L \\leq h(x) - L. \\tag{3}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let $\\delta$ be the minimum of $\\delta_f$, $\\delta_h$, and $\\delta_g$.  Then by the transitivity of inequality, we can substitute $\\delta$ in for the previous deltas in (1), (2), and (3).  So with our $\\delta > 0$ we have:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 <|x-c| < \\delta \\rightarrow& -\\epsilon < f(x) - L < \\epsilon, \\\\\n",
    "& -\\epsilon < h(x) - L < \\epsilon, \\\\\n",
    "& f(x) - L \\leq g(x) - L \\leq h(x) - L \\\\\n",
    "0 < |x-c| < \\delta \\rightarrow& -\\epsilon < g(x) - L < \\epsilon\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So by the definition of a limit:\n",
    "\n",
    "$$ \\lim_{x\\to c} g(x) = L. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4fBrNzlkqfA"
   },
   "source": [
    "\n",
    "### Tricky Trig Squeeze Proofs\n",
    "\n",
    "$$ \\lim_{\\theta\\to 0} \\frac{\\sin{\\theta}}{\\theta} = 1$$ \n",
    "\n",
    "_Proof_: We [geometrically see](https://i.stack.imgur.com/UdlyK.gif) that while we're in the first quadrant ($ 0 < x < \\frac{\\pi}{2} $):\n",
    "\n",
    "$$ \n",
    "\\frac{|\\sin{\\theta}|}{2} \\leq \\frac{|\\theta|}{2} \\leq \\frac{|\\tan{\\theta}|}{2}. \n",
    "$$ \n",
    "\n",
    "so from that we get:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "|\\sin{\\theta}| \\leq |\\theta| \\leq |\\tan{\\theta}| \\\\\n",
    "|\\sin{\\theta}| \\leq |\\theta| \\leq \\frac{|\\sin{\\theta|}}{|\\cos{\\theta}|}  \\\\\n",
    "1 \\leq \\frac{|\\theta|}{|\\sin{\\theta}|} \\leq \\frac{1}{|\\cos{\\theta}|} \\\\\n",
    "1 \\geq \\frac{|\\sin{\\theta}|}{|\\theta|} \\geq |\\cos{\\theta}| \\\\\n",
    "1 \\geq \\frac{\\sin{\\theta}}{\\theta} \\geq \\cos{\\theta} \\quad\\text{Signs don't matter for 1st and 4th unit circle quadrants} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then by the Squeeze Theorem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lim_{\\theta\\to 0}1 \\geq \\lim_{\\theta\\to 0}\\frac{\\sin{\\theta}}{\\theta} \\geq \\lim_{\\theta\\to 0}\\cos{\\theta} \\\\\n",
    "1 \\geq \\lim_{\\theta\\to 0}\\frac{\\sin{\\theta}}{\\theta} \\geq 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(Note: I will eventually give a more rigorous explanation once I move into differential/taylor series definition of trig functions).\n",
    "\n",
    "Now how about:\n",
    "\n",
    "$$\n",
    "\\lim_{\\theta\\to 0} \\frac{1 - \\cos{\\theta}}{\\theta} = 0\n",
    "$$\n",
    "\n",
    "We can prove that as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{1 - \\cos{\\theta}}{\\theta} \\\\\n",
    "(\\frac{1 - \\cos{\\theta}}{\\theta})(\\frac{1 + \\cos{\\theta}}{1 + \\cos{\\theta}}) \\\\\n",
    "\\frac{1 - \\cos^2}{(\\theta)(1 + \\cos{\\theta})} \\\\\n",
    "\\frac{\\sin^2{\\theta}}{(\\theta)(1 + \\cos{\\theta})} \\\\\n",
    "(\\frac{\\sin{\\theta}}{\\theta})(\\frac{\\sin{\\theta}}{1 + \\cos{\\theta}}) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then we take the limit by the product rule:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "(\\lim_{\\theta\\to 0} \\frac{\\sin{\\theta}}{\\theta}) (\\lim_{\\theta\\to 0} \\frac{\\sin{\\theta}}{1 + \\cos{\\theta}}) \\\\\n",
    "(1)(0/2) \\\\\n",
    "0 \\\\\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trig Limits\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to 0}\\frac{\\sin{x}}{x} = 1 \\\\\n",
    "\\lim_{x\\to 0}\\frac{1 - \\cos{x}}{x} = 0 \\\\\n",
    "$$\n",
    "\n",
    "These are proved using the Squeeze Theorem, I followed along with the Khan proofs on that.  These limits are necessary for proving the derivatives of Trig functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Limits at Infinity\n",
    "\n",
    "### Vertical Asymptotes\n",
    "$$\n",
    "\\lim_{x\\to a}f(x) = \\infty\n",
    "$$\n",
    "\n",
    "means\n",
    "\n",
    "$$\n",
    "\\forall M>0 ~\\exists \\delta > 0 ~\\forall x: \\\\\n",
    "0 < |x - a| < \\delta \\rightarrow f(x) > M\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to a}f(x) = -\\infty\n",
    "$$\n",
    "\n",
    "means\n",
    "\n",
    "$$\n",
    "\\forall N<0 ~\\exists \\delta > 0 ~\\forall x: \\\\\n",
    "0 < |x - a| < \\delta \\rightarrow f(x) < N\n",
    "$$\n",
    "\n",
    "\n",
    "### Horizontal Asymptotes\n",
    "$$\n",
    "\\lim_{x\\to \\infty}f(x) = L\n",
    "$$\n",
    "\n",
    "means\n",
    "\n",
    "$$\n",
    "\\forall \\epsilon>0 ~\\exists M > 0 ~\\forall x: \\\\\n",
    "x > M \\rightarrow |f(x) - L| < \\epsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to -\\infty}f(x) = L\n",
    "$$\n",
    "\n",
    "means\n",
    "\n",
    "$$\n",
    "\\forall \\epsilon>0 ~\\exists M < 0 ~\\forall x: \\\\\n",
    "x < M \\rightarrow |f(x) - L| < \\epsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to \\infty}f(x) = \\infty\n",
    "$$\n",
    "\n",
    "means\n",
    "$$\n",
    "\\forall N>0 ~\\exists M > 0 ~\\forall x: \\\\\n",
    "x > M \\rightarrow f(x) > N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Biggest Term Wins in an Infinite Limit\n",
    "\n",
    "If $p(x)=a_nx^n+a_{n−1}x^{n−1}+\\dots a_1x +a_0$ is a polynomial of degree n (i.e. $a_n \\ne 0$) then,\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to \\infty}p(x)= \\lim_{x\\to \\infty}a_nx^n\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to -\\infty}p(x)= \\lim_{x\\to -\\infty}a_nx^n\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuity\n",
    "\n",
    "$f$ is continuous at $x=c$ if:\n",
    "\n",
    "$$\\forall \\epsilon > 0 ~\\exists \\delta > 0: \\forall x[|x-c < \\delta \\rightarrow |f(x) - f(c)| < \\epsilon] $$\n",
    "\n",
    "Note that this requires $f(c)$ to exist.\n",
    "\n",
    "Types of Discontinuities:\n",
    "- Point/Removable\n",
    "- Jump Discontinuity\n",
    "- Asymptotic Discontinuity\n",
    "\n",
    "$f$ is continuous over an interval $[a, b]$, if it is continuous at very point in the interval:\n",
    "\n",
    "$$\\forall c \\in [a,b] ~\\forall \\epsilon > 0 ~\\exists \\delta > 0: \\forall x[|x-c < \\delta \\rightarrow |f(x) - f(c)| < \\epsilon] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit Chain Rule\n",
    "\n",
    "This is a huge one, because like any other chain rule, you can build up a huge number of things with f(g(x)).  It's basically telling you when you can do substitution in this context.\n",
    "\n",
    "Going to state two forms of the rule, the simpler / more powerful one with continuity, and the more general but less powerful w/o continuity one.\n",
    "\n",
    "## Limit Chain Rule with Continuity\n",
    "\n",
    "If  \n",
    "\n",
    "$$\n",
    "\\lim_{x\\to b}f(x) = f(b), \\lim_{x\\to a}g(x) = b\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to a}f(g(x)) = f(b)\n",
    "$$\n",
    "\n",
    "## General Limit Chain Rule\n",
    "\n",
    "If \n",
    "\n",
    "$$\n",
    "\\lim_{x\\to b}f(x) = c, \\lim_{x\\to a}g(x) = b\n",
    "$$\n",
    "\n",
    "And one of these conditions is true:\n",
    "1. $f$ is continuous at $x=b$ like above, OR\n",
    "2. $g$ does not take the value $b$ near $a$ i.e. $\\Delta > 0:$\n",
    "\n",
    "$$\n",
    "0 < |x-a| < \\Delta \\Rightarrow |g(x) - b| > 0\n",
    "$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to a}f(g(x)) = c\n",
    "$$\n",
    "\n",
    "### Examples\n",
    "\n",
    "$$\n",
    "f(x) = g(x)\n",
    "\\begin{cases}\n",
    "0 ~&\\text{ if }~ x \\ne 0 \\\\\n",
    "1 ~&\\text{ if }~ x = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This one fails to satisfy the rule, so applying the rule gives the wrong answer (0 instead of 1).\n",
    "\n",
    "$$\n",
    "f(x)\n",
    "\\begin{cases}\n",
    "x ~&\\text{ if }~ x \\ne 1 \\\\\n",
    "0 ~&\\text{ if }~ x = 1\n",
    "\\end{cases} \\\\\n",
    "g(x) = x \\\\\n",
    "$$\n",
    "\n",
    "In this case, $f(x)$ is not continuous at $1$, but the rule works because the 2nd condition holds.\n",
    "\n",
    "Consider inner function\n",
    "\n",
    "$$\n",
    "g(x) = \n",
    "\\begin{cases}\n",
    "\\frac{x}{\\sin(\\frac{1}{x})} ~&\\text{ if }~ x \\ne 0 \\\\\n",
    "0 ~&\\text{ if }~ x = 0\n",
    "\\end{cases} \\\\\n",
    "$$\n",
    "\n",
    "If you're dealing with this $g(x)$, then you have a pretty fascinating function that breaks the 2nd condition despite being continuous and not having any horizontal line in it.\n",
    "\n",
    "### Proofs\n",
    "\n",
    "The continuity one is proven on [lamar.edu](https://tutorial.math.lamar.edu/classes/calci/limitproofs.aspx).  The more general one is proven on [proofwiki](https://proofwiki.org/wiki/Limit_of_Composite_Function).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existence Theorems\n",
    "\n",
    "All of these require some analysis to prove in a smooth way.  So I'm just gonna state them and relevant nuances here.\n",
    "\n",
    "## Intermediate Value Theorem\n",
    "\n",
    "If $f$ is a continuous function whose domain contains the interval $[a, b]$, then it takes on any given value between $f(a)$ and $f(b)$ at some point within the interval.\n",
    "\n",
    "\"The theorem depends on, and is equivalent to, the completeness of the real numbers.\" - https://en.wikipedia.org/wiki/Intermediate_value_theorem\n",
    "\n",
    "## Mean Value Theorem\n",
    "\n",
    "If\n",
    "\n",
    "- $f$ is continuous over the _closed interval_ $[a,b]$, and\n",
    "- Differentiable on the _open interval_ $(a,b)$\n",
    "\n",
    "Then at some point the average rate of change (secant) must be equal to the instantaneous rate of change (tangent):\n",
    "\n",
    "$$\\frac{f(b) - f(a)}{b-a} = f'(c)$$\n",
    "\n",
    "## Extreme Value Theorem\n",
    "\n",
    "If $f$ is continuous on $[a, b]$,\n",
    "\n",
    "$$\\exists c,d \\in [a,b]: f(c) \\leq f(x) \\leq f(d) \\forall x \\in [a,b]$$\n",
    "\n",
    "Note that without continuity, you cannot get an exact max value or min value.  Continuity is necessary but not sufficient for a global min/max.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining $e$\n",
    "\n",
    "$$ \n",
    "\\lim_{n\\to \\infty} (1 + \\frac{1}{n})^n\n",
    "$$\n",
    "\n",
    "or alternately\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to 0} (1 + n)^\\frac{1}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri9S0znqkqfB"
   },
   "source": [
    "# Differentiation\n",
    "\n",
    "Differential calculus is all about instantaneous rate of change. **Secant** lines give you average rate of change at an interval, as opposed to **Tangent** line giving you instantaneous rate of change.\n",
    "\n",
    "**Differentials** are things like $\\Delta x$ (change in variable) or $\\Delta y$ (change in value, which can be labeled $dx$, $dy$.  So we have $\\frac{dy}{dx}$ meaning the derivative, i.e. the ratio between change in value and change in variable.\n",
    "\n",
    "Notation wise I will use both $f'(x)$ and $\\frac{d}{dx}$.  $\\frac{dy}{dx}$ is used when you have a value $y$, but you'd put $\\frac{d}{dx}$ before the actual function. [Reddit Thread](https://www.reddit.com/r/learnmath/comments/bjlyjw/whats_the_difference_between_ddx_and_dydx/).\n",
    "\n",
    "\n",
    "## Definition of a Derivative\n",
    "So for getting instantaneous change (the **Derivative**) we want:\n",
    "\n",
    "$$\n",
    "\\lim_{x\\to 0}\\frac{\\Delta y}{\\Delta x}\n",
    "$$\n",
    "\n",
    "which leads to our definitions of derivative as a function of $x$ and at a specific point..\n",
    "\n",
    "## Definition as a function of x\n",
    "$$ f'(x) = \\lim_{\\Delta x\\to0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x} $$\n",
    "\n",
    "Formal Definition:\n",
    "\n",
    "$$\\forall \\epsilon > 0 ~\\exists \\delta > 0 \\;\\forall \\Delta x: \\\\\n",
    "0<|\\Delta x| < \\delta \\implies \\left|\\frac{f(x + \\Delta x) - f(x)}{\\Delta x}-L\\right| < \\epsilon$$\n",
    "\n",
    "## Definition at a specific point\n",
    "$$ f'(c) = \\lim_{x\\to c} \\frac{f(x) - f(c)}{x - c} $$\n",
    "\n",
    "Formal Definition:\n",
    "\n",
    "$$\n",
    "\\forall \\epsilon > 0 ~\\exists \\delta > 0 \\forall x: \\\\\n",
    "0 < |x-c| < \\delta \\rightarrow |\\frac{f(x)-f(c)}{x-c} - L| < \\epsilon\n",
    "$$\n",
    "\n",
    "## Differentiability (at a specific point)\n",
    "\n",
    "Differentiability just means the limit in the definition of a derative exists at a point.\n",
    "\n",
    "Continuity at a point means\n",
    "$$ \\lim_{x\\to c}f(x) = f(c) $$\n",
    "\n",
    "Continuity is necessary, but not sufficient for differentiability.  Differentiability at a point requires that the limit works from both left and right of c.\n",
    "\n",
    "Proof that differentiability requires continuity.  Assume differentiability and:\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "& \\lim_{x\\to c}f(x) - f(c) \\\\\n",
    "& \\lim_{x\\to c} \\frac{(x-c)(f(x) -f(c))}{(x-c)} \\\\\n",
    "& \\lim_{x\\to c} (x-c) \\lim_{x\\to c} \\frac{(f(x) -f(c))}{(x-c)} \\quad\\text {Limit assumed to exist} \\\\\n",
    "& (0)\\lim_{x\\to c} \\frac{(f(x) -f(c))}{(x-c)} \\\\\n",
    "& \\lim_{x\\to c}(f(x) - f(c)) = 0 \\\\ \n",
    "& \\lim_{x\\to c}f(x) - \\lim_{x\\to c}f(c) = 0 \\\\\n",
    "& \\lim_{x\\to c}f(x) - f(c) = 0 \\\\\n",
    "& \\lim_{x\\to c}f(x) = f(c)\n",
    "\\end{align*} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Derivatives of Trig Functions\n",
    "\n",
    "I followed [Khan Academy proofs for these](https://www.khanacademy.org/math/ap-calculus-bc/bc-differentiation-1-new/bc-2-7/a/proving-the-derivatives-of-sinx-and-cosx?modal=1) in my notebook.  See above for the prerequisite limits proved by Squeeze Theorem used to prove these. And see Trig Notebook for pre-req identities, unit circle, etc.\n",
    "\n",
    "The derivative of $tan(x)$ can be solved using the quotient rule and pythagorean trig identity:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\frac{\\sin{x}}{\\cos{x}} = \\frac{\\cos^2{x} + \\sin^2{x}}{\\cos^2{x}} = \\frac{1}{\\cos^2{x}} = \\sec^2{x}\n",
    "$$\n",
    "\n",
    "### Derivatives of Inverse Trig Functions\n",
    "You get these by applying the inverse function rule (derived from the chain rule), but here they are for reference:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\arcsin{x} = \\frac{1}{\\sqrt{1 - x^2}} \\quad\\text{$x \\ne \\pm 1$} \\\\\n",
    "\\frac{d}{dx}\\arccos{x} = \\frac{-1}{\\sqrt{1 - x^2}} \\quad\\text{$x \\ne \\pm 1$} \\\\\n",
    "\\frac{d}{dx}\\arctan{x} = \\frac{1}{1 + x^2} \\\\\n",
    "$$\n",
    "\n",
    "### Derivatives of Reciprocal Trig Functions\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\sec{x} = \\tan{x}\\sec{x} \\\\\n",
    "\\frac{d}{dx}\\csc{x} = -\\cot{x}\\csc{x} \\\\\n",
    "\\frac{d}{dx}\\cot{x} = -\\frac{1}{\\sin^2{x}} = -\\csc^2{x} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Derivative of $e^x$ and $ln(x)$\n",
    "\n",
    "$$\\frac{d}{dx}e^x = e^x $$\n",
    "\n",
    "I followed along with this [limit based proof from Khan](https://www.khanacademy.org/math/ap-calculus-bc/bc-differentiation-1-new/bc-2-7/a/proof-the-derivative-of-is?modal=1) in my notebook.\n",
    "\n",
    "$$\\frac{d}{dx}\\ln(x) = \\frac{1}{x} $$\n",
    "\n",
    "[This proof on Khan](https://www.khanacademy.org/math/ap-calculus-bc/bc-differentiation-1-new/bc-2-7/a/proof-the-derivative-of-lnx-is-1x?modal=1) is much faster using Implicit Differentiation.\n",
    "\n",
    "## Derivative Notation\n",
    "\n",
    "[Article on Wiki](https://en.wikipedia.org/wiki/Notation_for_differentiation)\n",
    "\n",
    "### Leibniz Notation\n",
    "$$y = f(x)$$\n",
    "\n",
    "Derivative of y is given by\n",
    "\n",
    "$$\\frac{dy}{dx}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative Properties\n",
    "\n",
    "Proofs via [Lamar](https://tutorial.math.lamar.edu/classes/calci/DerivativeProofs.aspx).  \n",
    "\n",
    "## Basic Properties\n",
    "\n",
    "**Sum/Difference of Two Functions**:\n",
    "$$\n",
    "(f(x) \\pm g(x))' = f'(x) \\pm g'(x)\n",
    "$$\n",
    "\n",
    "**Constant Times a Function**:\n",
    "$$\n",
    "(cf(x))'=cf'(x)\n",
    "$$\n",
    "\n",
    "**Derivative of a Constant**:\n",
    "$$\n",
    "\\frac{d}{dx}(c) = 0\n",
    "$$\n",
    "\n",
    "## Power Rule\n",
    "\n",
    "$$ \\frac{d}{dx}[x^n] = nx^{n-1} $$\n",
    "\n",
    "### Proof for positive n\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "& \\frac{d}{dx}[x^n] \\\\\n",
    "& \\lim_{\\Delta x\\to0} \\frac{(x + \\Delta x)^n - x^n}{\\Delta x}  \\quad\\text {Definition of a Limit} \\\\\n",
    "& \\lim_{\\Delta x\\to0} \\frac{\\sum\\limits_{k=0}^{n}\\binom{n}{k}x^{n-k}\\Delta x^k) - x^n}{\\Delta x}  \\quad\\text {Binomial Theorem} \\\\\n",
    "& \\lim_{\\Delta x\\to0} \\frac{\\binom{n}{0}x^n \\Delta x^0 + \\sum\\limits_{k=1}^{n}\\binom{n}{k}x^{n-k}\\Delta x^k) - x^n}{\\Delta x} \\\\\n",
    "& \\lim_{\\Delta x\\to0} \\frac{\\sum\\limits_{k=1}^{n}\\binom{n}{k}x^{n-k}\\Delta x^k)}{\\Delta x} \\\\\n",
    "& \\lim_{\\Delta x\\to0} {\\sum\\limits_{k=1}^{n}\\binom{n}{k}x^{n-k}\\Delta x^{k-1})} \\\\\n",
    "& \\lim_{\\Delta x\\to0} \\binom{n}{1} x^{n-1}\\Delta x^{1-1} + (0) \\quad\\text {delta x is 0 factor for k>1} \\\\\n",
    "& \\lim_{\\Delta x\\to0} nx^{n-1} = nx^{n-1} \\\\\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "This proof does not cover non-positive integers, so actually want to use logarithmic differentiation instead.  Proof is way easier!\n",
    "\n",
    "\n",
    "### Proof for all n\n",
    "\n",
    "$$\n",
    "y = x^n \\\\\n",
    "\\ln(y) = \\ln(x^n) \\\\\n",
    "\\ln(y) = n\\ln(x) \\\\\n",
    "\\frac{d}{dx}\\ln(y) = \\frac{d}{dx} n\\ln(x) \\\\\n",
    "\\frac{y'}{y} = nx^{-1} \\\\\n",
    "y' = nx^{-1}\n",
    "$$\n",
    "\n",
    "The power of logarithmic differentation.  But also [check out this approach](https://math.stackexchange.com/questions/4349120/solving-derivative-of-xx-without-logarithmic-differentiation) with putting it in terms of $e$.\n",
    "\n",
    "## Product Rule\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}f(x)g(x) = f'(x)g(x) + f(x)g'(x)\n",
    "$$\n",
    "\n",
    "I followed the [limit based proof](https://www.khanacademy.org/math/ap-calculus-bc/bc-differentiation-1-new/bc-2-8/a/proving-the-product-rule?modal=1), which features a clever substitution from Khan.  But it's much simpler with Logarithmic Differentiation.\n",
    "\n",
    "\n",
    "## Quotient Rule\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\frac{f(x)}{g(x)} = \\frac{g(x)f'(x) - f(x)g'(x)}{g(x)^2} \\quad\\text{where g(x) != 0}\n",
    "$$\n",
    "\n",
    "This can be proven from the product rule combined with the chain rule.  Or more simply with Logarithmic Differentiation.\n",
    "\n",
    "## Chain Rule\n",
    "\n",
    "If $f(x)$ and $g(x)$ are both differentiable functions and we define $h(x)=f(g(x))$ then the derivative of h(x) is $$h'(x)=f'(g(x))g'(x)$$\n",
    "\n",
    "The chain rule proof is actually a bit tricky, there's a \"naive\" proof which doesn't protect from division by 0.  You use a couple of piecewise functions to guarantee continuity and avoid this.\n",
    "\n",
    "### Derivative of inverse functions\n",
    "\n",
    "This comes from the chain rule:\n",
    "\n",
    "$$\n",
    "f^{-1}\\prime(x) = \\frac{1}{f\\prime(f^{-1}(x)}\n",
    "$$\n",
    "\n",
    "### Derivative of $a^x$ and $\\log_a{x}$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}a^x = (ln(a))e^x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\log_a{x} = \\frac{1}{ln(a)x}\n",
    "$$\n",
    "\n",
    "### Implicit differentiation\n",
    "\n",
    "Basically just treat y like the function of x that it is, and you can apply the chian rule without rearranging y to be by itself.\n",
    "\n",
    "# Derivative Techniques\n",
    "\n",
    "## Logarithmic Differentiation\n",
    "\n",
    "Taking derivatives of some functions can be simplified by using logarithms.  This is called **logarithmic differentiation**, which is a combo of:\n",
    "\n",
    "- $\\ln$ both sides\n",
    "- simplify using log properties\n",
    "- implicit differentiation\n",
    "\n",
    "The log properties can help with an ugly multiple product rule function, but there are also certain functions they work really well with of the form $f(x)^{g(x)}$.  Specifically check the proof of $\\frac{d}{dx}x^x$ above. Note that derivatives like this can also be solved by plugging in something like $e^{\\ln(x)}$.  Basically the point is that getting things in terms of natural logs or the exponential function is really nice.\n",
    "\n",
    "Logarithmic differentiation allows for a complete proof of product rule for all $n$, not just positive (see above), and simpler proofs of the product and quotient rules.\n",
    "\n",
    "## L'Hopital's Rule\n",
    "\n",
    "Previously we solved derivatives using limits, now we're gonna do the reverse and solve limits with derivatives.  Specifically, we will use it to solve derivatives of indeterminate forms.\n",
    "\n",
    "If $\\lim\\limits_{x \\to c}f(x) = \\lim\\limits_{x \\to c}g(x) \\in \\{0, \\pm \\infty\\}$ and $\\lim\\limits_{x \\to c}\\frac{f'(x)}{g'(x)} = L$\n",
    "\n",
    "Then $\\lim\\limits_{x \\to c}\\frac{f(x)}{g(x)} = L$\n",
    "\n",
    "Note that $\\frac{\\infty}{-\\infty}$ is allowed, and I'm pretty sure the above requirements let you use $c = \\pm \\infty$, but definitely the strong version of L'Hopital's rule allow **extended real numbers** ($\\{\\mathbb{R}, \\pm \\infty\\}$).\n",
    "\n",
    "The proof of this requires Analysis.. At which point it's also possible to state it somewhat more strongly, which I'll save for that context.  The $\\frac{0}{0}$, with $c$ being a real number is much simpler and done by Khan which I followed along with.  The proper application of L'Hopital rule [can be tricky](https://math.stackexchange.com/questions/4354717/understanding-the-counterexamples-to-lhopitals-rule).\n",
    "\n",
    "You can usually find a clever way to apply L'Hopital's rule on non-fractional indeterminate forms.. Here's a. example:\n",
    "\n",
    "$$ x\\ln{x} = \\frac{\\ln{x}}{\\frac{1}{x}} $$\n",
    "\n",
    "Other times it's a substitution, or multiplying by the right thing to get it in L'Hopital form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of Derivatives\n",
    "\n",
    "# Linear Approximation\n",
    "\n",
    "Allows us to handle equations like $\\sqrt{4.36}$ approximately.  In general, you can zoom in on diferentiable functions and they'll take on local linearity.  If you zoom in and get a vertical line looking thing, you're dealing ith a vertical asymptote.\n",
    "\n",
    "**Equation for linear approximation**:\n",
    "\n",
    "$$ f(x) \\approx f(a) + f'(a)(x-a) $$\n",
    "\n",
    "## Critical Points\n",
    "\n",
    "Points where $f(a)$ is defined and $f'(a)$ is 0 or undefined are called **critical points**.  \n",
    "\n",
    "Critical Points are necessary but not sufficient to be a local min or max.\n",
    "\n",
    "## Min and Max Values\n",
    "\n",
    "**Relative Maximum** and **Relative Minimum** are compared to their neighborhood of points..  Mathematical definition:\n",
    "\n",
    "$f(c)$ is a relative max if:\n",
    "\n",
    "$$\n",
    "\\exists ~h>0 \\forall x \\in (c-h, c+h): f(c) \\geq f(x) \n",
    "$$\n",
    "\n",
    "$f(c)$ is a relative min if:\n",
    "\n",
    "$$\n",
    "\\exists ~h>0 \\forall x \\in (c-h, c+h): f(c) \\leq f(x) \n",
    "$$\n",
    "\n",
    "\n",
    "Relative max and relative min are collectively called **relative extrema**.  \n",
    "\n",
    "If $f'(x)$ switches from positive to negative we are at a local max.  If neg->pos that's a local min.\n",
    "\n",
    "**Absolute extrema** are min or max of the whole domain, or the interval of the function being looked at.  Finding absolute extrema on a closed interval, just find the relative extrema and consider the endpoints.\n",
    "\n",
    "Note that there maybe no specific absolute min or max values, e.g. function could go to $\\pm \\infty$ on each side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Concavity\n",
    "\n",
    "Here's a pic and good explanation https://tutorial.math.lamar.edu/Classes/CalcI/ShapeofGraphPtII.aspx\n",
    "\n",
    "Concave Down $\\rightarrow f''(x) < 0$\n",
    "\n",
    "Concave Up $\\rightarrow f''(x) > 0$\n",
    "\n",
    "Concave Down on a critical point means you have a Max. Concave Up on a critical points means you have a Min.\n",
    "\n",
    "## Inflection Points\n",
    "\n",
    "An inflection point is when concavity changes, i.e. the sign of $f''(x)$ changes. Visually, you can see this typically but could be subtle unless youzoom in. Inflection Point is approached the same as a min/max, but with an extra derivative: Points where $f'(a)$ is defined and $f''(a)$ is 0 are where we search for inflections.\n",
    "\n",
    "Minima/Maxima techniques are great for optimization problems.  Most optimization problems involve finding critical points w/ $f'(x)$ and checking inflections w/ $f''(x)$ with...\n",
    "\n",
    "## Second Derivative Test\n",
    "\n",
    "If $f'(c) = 0$, $f'$ exists in a neighborhood around $x-c$ [have to learn analysis to properly parse this], then:\n",
    "\n",
    "- $f''(c)<0 \\rightarrow $ relative max value at $x=c$.\n",
    "- $f''(c)=0 \\rightarrow $ inconclusive.\n",
    "- $f''(c)>0 \\rightarrow $ relative min value at $x=c$.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Calculus.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
