{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification errors on validation: {3: 0.3, 4: 0.5, 5: 0.2, 6: 0.0, 7: 0.1}\n",
      "Classification errors on testing: {3: 0.396, 4: 0.388, 5: 0.284, 6: 0.192, 7: 0.196}\n",
      "Classification errors w/ smaller training on validation: {3: 0.28, 4: 0.36, 5: 0.2, 6: 0.08, 7: 0.12}\n",
      "Classification errors w/ smaller training on testing: {3: 0.396, 4: 0.388, 5: 0.284, 6: 0.192, 7: 0.196}\n"
     ]
    }
   ],
   "source": [
    "# https://work.caltech.edu/homework/hw7.pdf\n",
    "# Problems 1-5\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "training_and_validation_data = pd.read_csv('in.dta', sep='\\s+', header=None)\n",
    "\n",
    "# Split in.dta into training (first 25 examples) and validation (last 10 examples).  \n",
    "\n",
    "training_data = training_and_validation_data.iloc[:25,:].to_numpy()\n",
    "validation_data = training_and_validation_data.iloc[25:,:].to_numpy()\n",
    "\n",
    "phi = [\n",
    "    lambda xs: np.ones(len(xs)),\n",
    "    lambda xs: xs[:, 0],\n",
    "    lambda xs: xs[:, 1],\n",
    "    lambda xs: xs[:, 0] ** 2,\n",
    "    lambda xs: xs[:, 1] ** 2,\n",
    "    lambda xs: xs[:, 0] * xs[:, 1],\n",
    "    lambda xs: np.abs(xs[:, 0] - xs[:, 1]),\n",
    "    lambda xs: np.abs(xs[: , 0] + xs[:, 1])\n",
    "]\n",
    "\n",
    "training_xs = training_data[:,0:2]\n",
    "training_ys = training_data[:,2]\n",
    "\n",
    "validation_xs = validation_data[:,0:2]\n",
    "validation_ys = validation_data[:,2]\n",
    "\n",
    "testing_data = pd.read_csv('out.dta', sep='\\s+', header=None).to_numpy()\n",
    "testing_xs = testing_data[:,0:2]\n",
    "testing_ys = testing_data[:,2]\n",
    "\n",
    "def transform_data(xs, k):\n",
    "    zs = []\n",
    "    for i in range(0, k + 1):\n",
    "        transformed = phi[i](xs)\n",
    "        zs.append(transformed)\n",
    "    \n",
    "    return np.column_stack(tuple(zs))\n",
    "\n",
    "def pseudo_inverse(xs):\n",
    "    return np.linalg.inv(xs.T @ xs) @ xs.T\n",
    "\n",
    "validation_errs = {}\n",
    "testing_errs = {}\n",
    "small_train_validation_errs = {}\n",
    "small_train_testing_errs = {}\n",
    "\n",
    "# Train on the 25 examples only, using the validation set of 10 examples to select between five models that apply linear regression to phi_0 through phi_k, with k = 3,4,5,6,7. \n",
    "for k in range(3, 7 + 1):\n",
    "    training_zs = transform_data(training_xs, k)\n",
    "    weights = pseudo_inverse(training_zs) @ training_ys\n",
    "\n",
    "    validation_zs = transform_data(validation_xs, k)\n",
    "    predicted_ys = np.sign(validation_zs @ weights)\n",
    "    \n",
    "    misclassified_points = np.flatnonzero(predicted_ys != validation_ys)\n",
    "    validation_errs[k] = len(misclassified_points) / len(validation_xs)\n",
    "\n",
    "    testing_zs = transform_data(testing_xs, k)\n",
    "    predicted_ys = np.sign(testing_zs @ weights)\n",
    "\n",
    "    misclassified_points = np.flatnonzero(predicted_ys != testing_ys)\n",
    "    testing_errs[k] = len(misclassified_points) / len(testing_xs)\n",
    "\n",
    "    # Now let's switch validation and training sets\n",
    "    weights = pseudo_inverse(validation_zs) @ validation_ys\n",
    "    predicted_ys = np.sign(training_zs @ weights)\n",
    "\n",
    "    misclassified_points = np.flatnonzero(predicted_ys != training_ys)\n",
    "    small_train_validation_errs[k] = len(misclassified_points) / len(training_xs)\n",
    "\n",
    "    predicted_ys = np.sign(testing_zs @ weights)\n",
    "    misclassified_points = np.flatnonzero(predicted_ys != testing_ys)\n",
    "    testing_errs[k] = len(misclassified_points) / len(testing_xs)\n",
    "\n",
    "    small_train_testing_errs[k] = len(misclassified_points) / len(testing_xs)\n",
    "\n",
    "\n",
    "# 1. For which model is the classification err on the validation set smallest?\n",
    "print(\"Classification errors on validation:\", validation_errs)\n",
    "\n",
    "# 2. Evaluate the out-of-sample classification error using out.dta on the 5 models to see how well the validation set predicted the best of the 5 models. For which model is the out-of-sample classification error smallest?\n",
    "print(\"Classification errors on testing:\", testing_errs)\n",
    "\n",
    "\n",
    "# Reverse the role of training and validation sets; now training with the last 10 examples and validating with the first 25 examples. \n",
    "# \n",
    "# 3. For which model is the classification error on the validation set smallest?\n",
    "print(\"Classification errors w/ smaller training on validation:\", small_train_validation_errs)\n",
    "\n",
    "# 4. Once again, evaluate the out-of-sample classification error using out.dta on the 5 models to see how well the validation set predicted the best of the 5 models. For which model is the out-of-sample classification error smallest?\n",
    "print(\"Classification errors w/ smaller training on testing:\", small_train_testing_errs)\n",
    "\n",
    "# 5. What values are closest in Euclidean distance to the out-of-sample classification error obtained for the model chosen in Problems 1 and 3, respectively?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6\n",
    "\n",
    "np.unif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
