{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Course here](https://deeplearning.neuromatch.io/tutorials/intro.html)\n",
    "\n",
    "# Basics and PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title Install and import feedback gadget\n",
    "!pip3 install vibecheck datatops --quiet\n",
    "\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "def content_review(notebook_section: str):\n",
    "    return DatatopsContentReviewContainer(\n",
    "        \"\",  # No text prompt\n",
    "        notebook_section,\n",
    "        {\n",
    "            \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "            \"name\": \"neuromatch_dl\",\n",
    "            \"user_key\": \"f379rz8y\",\n",
    "        },\n",
    "    ).render()\n",
    "\n",
    "\n",
    "feedback_prefix = \"W1D1_T1\"\n",
    "\n",
    "# Imports\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Figure settings\n",
    "# @title Figure Settings\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "import ipywidgets as widgets\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "# @title Helper Functions\n",
    "\n",
    "def checkExercise1(A, B, C, D):\n",
    "  \"\"\"\n",
    "  Helper function for checking Exercise 1.\n",
    "\n",
    "  Args:\n",
    "    A: torch.Tensor\n",
    "      Torch Tensor of shape (20, 21) consisting of ones.\n",
    "    B: torch.Tensor\n",
    "      Torch Tensor of size([3,4])\n",
    "    C: torch.Tensor\n",
    "      Torch Tensor of size([20,21])\n",
    "    D: torch.Tensor\n",
    "      Torch Tensor of size([19])\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  assert torch.equal(A.to(int),torch.ones(20, 21).to(int)), \"Got: {A} \\n Expected: {torch.ones(20, 21)} (shape: {torch.ones(20, 21).shape})\"\n",
    "  assert np.array_equal(B.numpy(),np.vander([1, 2, 3], 4)), \"Got: {B} \\n Expected: {np.vander([1, 2, 3], 4)} (shape: {np.vander([1, 2, 3], 4).shape})\"\n",
    "  assert C.shape == (20, 21), \"Got: {C} \\n Expected (shape: {(20, 21)})\"\n",
    "  assert torch.equal(D, torch.arange(4, 41, step=2)), \"Got {D} \\n Expected: {torch.arange(4, 41, step=2)} (shape: {torch.arange(4, 41, step=2).shape})\"\n",
    "  print(\"All correct\")\n",
    "\n",
    "def timeFun(f, dim, iterations, device='cpu'):\n",
    "  \"\"\"\n",
    "  Helper function to calculate amount of time taken per instance on CPU/GPU\n",
    "\n",
    "  Args:\n",
    "    f: BufferedReader IO instance\n",
    "      Function name for which to calculate computational time complexity\n",
    "    dim: Integer\n",
    "      Number of dimensions in instance in question\n",
    "    iterations: Integer\n",
    "      Number of iterations for instance in question\n",
    "    device: String\n",
    "      Device on which respective computation is to be run\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  iterations = iterations\n",
    "  t_total = 0\n",
    "  for _ in range(iterations):\n",
    "    start = time.time()\n",
    "    f(dim, device)\n",
    "    end = time.time()\n",
    "    t_total += end - start\n",
    "\n",
    "  if device == 'cpu':\n",
    "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")\n",
    "  else:\n",
    "    print(f\"time taken for {iterations} iterations of {f.__name__}({dim}, {device}): {t_total:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All correct\n"
     ]
    }
   ],
   "source": [
    "# Coding Exercise 2.1: Creating Tensors\n",
    "# https://deeplearning.neuromatch.io/tutorials/W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html#coding-exercise-2-1-creating-tensors\n",
    "\n",
    "import torch\n",
    "from torch.distributions.uniform import Uniform\n",
    "\n",
    "def tensor_creation(Z):\n",
    "  \"\"\"\n",
    "  A function that creates various tensors.\n",
    "\n",
    "  Args:\n",
    "    Z: numpy.ndarray\n",
    "      An array of shape (3,4)\n",
    "\n",
    "  Returns:\n",
    "    A : Tensor\n",
    "      20 by 21 tensor consisting of ones\n",
    "    B : Tensor\n",
    "      A tensor with elements equal to the elements of numpy array Z\n",
    "    C : Tensor\n",
    "      A tensor with the same number of elements as A but with values âˆ¼U(0,1)\n",
    "    D : Tensor\n",
    "      A 1D tensor containing the even numbers between 4 and 40 inclusive.\n",
    "  \"\"\"\n",
    "  A = torch.ones((20, 21))\n",
    "  B = torch.from_numpy(Z)\n",
    "  C = Uniform(0,1).sample((20, 21))\n",
    "  D = torch.arange(4,40 + 1,2)\n",
    "\n",
    "  return A, B, C, D\n",
    "\n",
    "\n",
    "# numpy array to copy later\n",
    "Z = np.vander([1, 2, 3], 4)\n",
    "\n",
    "# Uncomment below to check your function!\n",
    "A, B, C, D = tensor_creation(Z)\n",
    "checkExercise1(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Simple Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20, 24],\n",
      "        [31, 27]])\n",
      "tensor(82)\n"
     ]
    }
   ],
   "source": [
    "def simple_operations(a1: torch.Tensor, a2: torch.Tensor, a3: torch.Tensor):\n",
    "  \"\"\"\n",
    "  Helper function to demonstrate simple operations\n",
    "  i.e., Multiplication of tensor a1 with tensor a2 and then add it with tensor a3\n",
    "\n",
    "  Args:\n",
    "    a1: Torch tensor\n",
    "      Tensor of size ([2,2])\n",
    "    a2: Torch tensor\n",
    "      Tensor of size ([2,2])\n",
    "    a3: Torch tensor\n",
    "      Tensor of size ([2,2])\n",
    "\n",
    "  Returns:\n",
    "    answer: Torch tensor\n",
    "      Tensor of size ([2,2]) resulting from a1 multiplied with a2, added with a3\n",
    "  \"\"\"\n",
    "  answer = (a1 @ a2) + a3\n",
    "  return answer\n",
    "\n",
    "\n",
    "# Computing expression 1:\n",
    "\n",
    "# init our tensors\n",
    "a1 = torch.tensor([[2, 4], [5, 7]])\n",
    "a2 = torch.tensor([[1, 1], [2, 3]])\n",
    "a3 = torch.tensor([[10, 10], [12, 1]])\n",
    "## uncomment to test your function\n",
    "A = simple_operations(a1, a2, a3)\n",
    "print(A)\n",
    "\n",
    "def dot_product(b1: torch.Tensor, b2: torch.Tensor):\n",
    "  \"\"\"\n",
    "  Helper function to demonstrate dot product operation\n",
    "  Dot product is an algebraic operation that takes two equal-length sequences\n",
    "  (usually coordinate vectors), and returns a single number.\n",
    "  Geometrically, it is the product of the Euclidean magnitudes of the\n",
    "  two vectors and the cosine of the angle between them.\n",
    "\n",
    "  Args:\n",
    "    b1: Torch tensor\n",
    "      Tensor of size ([3])\n",
    "    b2: Torch tensor\n",
    "      Tensor of size ([3])\n",
    "\n",
    "  Returns:\n",
    "    product: Tensor\n",
    "      Tensor of size ([1]) resulting from b1 scalar multiplied with b2\n",
    "  \"\"\"\n",
    "  # Use torch.dot() to compute the dot product of two tensors\n",
    "  product = b1.dot(b2)\n",
    "  return product\n",
    "\n",
    "\n",
    "# Computing expression 2:\n",
    "b1 = torch.tensor([3, 5, 7])\n",
    "b2 = torch.tensor([2, 4, 8])\n",
    "## Uncomment to test your function\n",
    "b = dot_product(b1, b2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Manipulating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 24])\n",
      "tensor([[ 0,  2],\n",
      "        [ 1,  3],\n",
      "        [ 2, -1],\n",
      "        [ 3, 10]])\n",
      "tensor([[ 3,  2],\n",
      "        [-1,  5]])\n",
      "tensor([ 1, -1, -1,  3,  2,  3,  0])\n"
     ]
    }
   ],
   "source": [
    "def functionA(my_tensor1, my_tensor2):\n",
    "  \"\"\"\n",
    "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`\n",
    "  and returns the column sum of\n",
    "  `my_tensor1` multiplied by the sum of all the elmements of `my_tensor2`,\n",
    "  i.e., a scalar.\n",
    "\n",
    "  Args:\n",
    "    my_tensor1: torch.Tensor\n",
    "    my_tensor2: torch.Tensor\n",
    "\n",
    "  Retuns:\n",
    "    output: torch.Tensor\n",
    "      The multiplication of the column sum of `my_tensor1` by the sum of\n",
    "      `my_tensor2`.\n",
    "  \"\"\"\n",
    "  output = my_tensor1.sum(1) * my_tensor2.sum()\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "def functionB(my_tensor):\n",
    "  \"\"\"\n",
    "  This function takes in a square matrix `my_tensor` and returns a 2D tensor\n",
    "  consisting of a flattened `my_tensor` with the index of each element\n",
    "  appended to this tensor in the row dimension.\n",
    "\n",
    "  Args:\n",
    "    my_tensor: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "  \"\"\"\n",
    "  # flatten the tensor `my_tensor`\n",
    "  my_tensor = torch.reshape(my_tensor, (4,1))\n",
    "  # create the idx tensor to be concatenated to `my_tensor`\n",
    "  idx_tensor = torch.unsqueeze(torch.arange(0,len(my_tensor)), 1)\n",
    "  # concatenate the two tensors\n",
    "  output = torch.cat((idx_tensor, my_tensor), 1)\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "def functionC(my_tensor1, my_tensor2):\n",
    "  \"\"\"\n",
    "  This function takes in two 2D tensors `my_tensor1` and `my_tensor2`.\n",
    "  If the dimensions allow it, it returns the\n",
    "  elementwise sum of `my_tensor1`-shaped `my_tensor2`, and `my_tensor2`;\n",
    "  else this function returns a 1D tensor that is the concatenation of the\n",
    "  two tensors.\n",
    "\n",
    "  Args:\n",
    "    my_tensor1: torch.Tensor\n",
    "    my_tensor2: torch.Tensor\n",
    "\n",
    "  Returns:\n",
    "    output: torch.Tensor\n",
    "      Concatenated tensor.\n",
    "  \"\"\"\n",
    "  ################################################\n",
    "  # check we can reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "  if torch.numel(my_tensor1) == torch.numel(my_tensor2):\n",
    "    # reshape `my_tensor2` into the shape of `my_tensor1`\n",
    "    my_tensor2 = my_tensor2.reshape(my_tensor1.shape)\n",
    "    # sum the two tensors\n",
    "    output = my_tensor1 + my_tensor2\n",
    "  else:\n",
    "    # flatten both tensors\n",
    "    my_tensor1 = my_tensor1.flatten()\n",
    "    my_tensor2 = my_tensor2.flatten()\n",
    "    # concatenate the two tensors in the correct dimension\n",
    "    output = torch.cat((my_tensor1, my_tensor2))\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "## Implement the functions above and then uncomment the following lines to test your code\n",
    "print(functionA(torch.tensor([[1, 1], [1, 1]]), torch.tensor([[1, 2, 3], [1, 2, 3]])))\n",
    "print(functionB(torch.tensor([[2, 3], [-1, 10]])))\n",
    "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0, 2]])))\n",
    "print(functionC(torch.tensor([[1, -1], [-1, 3]]), torch.tensor([[2, 3, 0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUs\n",
    "\n",
    "When using Colab notebooks, by default, will not have access to a GPU. In order to start using GPUs we need to request one. We can do this by going to the runtime tab at the top of the page.\n",
    "\n",
    "By following Runtime â†’ Change runtime type and selecting GPU from the Hardware Accelerator dropdown list, we can start playing with sending tensors to GPUs.\n",
    "\n",
    "Once you have done this your runtime will restart and you will need to rerun the first setup cell to reimport PyTorch. Then proceed to the next cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
