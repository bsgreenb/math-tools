{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.64706706 -0.14505927  0.10154121 -2.03296844 -1.82804373  2.48152945\n",
      "  4.15893861  0.31651714]\n",
      "E_in unrestricted:  0.02857142857142857\n",
      "E_out unrestricted:  0.084\n",
      "E_in k = -3 0.02857142857142857\n",
      "E_out k = -3 0.08\n",
      "E_in k = -2 0.02857142857142857\n",
      "E_out k = -2 0.084\n",
      "E_in k = -1 0.02857142857142857\n",
      "E_out k = -1 0.056\n",
      "E_in k = 0 0.0\n",
      "E_out k = 0 0.092\n",
      "E_in k = 1 0.05714285714285714\n",
      "E_out k = 1 0.124\n",
      "E_in k = 2 0.2\n",
      "E_out k = 2 0.228\n"
     ]
    }
   ],
   "source": [
    "# Problems 2-6 on https://work.caltech.edu/homework/hw6.pdf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read values in from training\n",
    "training_data = pd.read_csv('work.caltech.edu_data_in.dta.txt', sep='\\s+', header=None)\n",
    "\n",
    "xs = training_data[training_data.columns[0:2]].to_numpy()\n",
    "training_ys = training_data[training_data.columns[2]].to_numpy()\n",
    "\n",
    "# Perform transforms\n",
    "training_n = len(xs)\n",
    "training_zs = np.column_stack((np.ones((training_n,1)), xs, np.square(xs[:, 0]), np.square(xs[:, 1]), xs[:, 0] * xs[:, 1], np.absolute(xs[:,0] - xs[:,1]), np.absolute(xs[:,0] + xs[:,1])))\n",
    "\n",
    "print(weights)\n",
    "weights = pseudo_inverse(training_zs) @ training_ys\n",
    "\n",
    "predicted_ys = np.sign(training_zs @ weights)\n",
    "misclassified_points = np.flatnonzero(predicted_ys != training_ys)\n",
    "\n",
    "# E_in = the fraction of in-sample points which got classified incorrectly\n",
    "e_in = len(misclassified_points) / training_n\n",
    "\n",
    "# Read values in from testing\n",
    "testing_data = pd.read_csv('work.caltech.edu_data_out.dta.txt', sep='\\s+', header=None)\n",
    "\n",
    "xs = testing_data[testing_data.columns[0:2]].to_numpy()\n",
    "testing_ys = testing_data[testing_data.columns[2]].to_numpy()\n",
    "\n",
    "# Transforms\n",
    "testing_n = len(xs)\n",
    "testing_zs = np.column_stack((np.ones((testing_n,1)), xs, np.square(xs[:, 0]), np.square(xs[:, 1]), xs[:, 0] * xs[:, 1], np.absolute(xs[:,0] - xs[:,1]), np.absolute(xs[:,0] + xs[:,1])))\n",
    "\n",
    "predicted_ys = np.sign(testing_zs @ weights)\n",
    "misclassified_points = np.flatnonzero(predicted_ys != testing_ys)\n",
    "# E_out = number of misclassified out-of-sample points / total number of out-of-sample points\n",
    "e_out = len(misclassified_points) / n\n",
    "\n",
    "print(\"E_in unrestricted: \", e_in)\n",
    "print(\"E_out unrestricted: \", e_out)\n",
    "\n",
    "\n",
    "# Next up, do it with weight decay... \n",
    "\n",
    "def pseudo_inverse_reg(xs, lamb):\n",
    "    return np.linalg.inv((xs.T @ xs) + (lamb * np.eye(xs.shape[1]))) @ xs.T\n",
    "\n",
    "# For lambda = 10**(-3)\n",
    "for k in range(-3, 4):  \n",
    "    lamb = 10 ** k\n",
    "\n",
    "    regularized_weights = pseudo_inverse_reg(training_zs, lamb) @ training_ys\n",
    "\n",
    "    # E_in = the fraction of in-sample points which got classified incorrectly\n",
    "    predicted_ys = np.sign(training_zs @ regularized_weights)\n",
    "    misclassified_points = np.flatnonzero(predicted_ys != training_ys)\n",
    "    e_in = len(misclassified_points) / training_n\n",
    "\n",
    "    # E_out = number of misclassified out-of-sample points / total number of out-of-sample points\n",
    "    predicted_ys = np.sign(testing_zs @ regularized_weights)\n",
    "    misclassified_points = np.flatnonzero(predicted_ys != testing_ys)\n",
    "    e_out = len(misclassified_points) / testing_n\n",
    "\n",
    "    print(\"E_in k = \" + str(k), e_in)\n",
    "    print(\"E_out k = \" + str(k), e_out)\n",
    "\n",
    "def pseudo_inverse(xs):\n",
    "    return np.linalg.inv(xs.T @ xs) @ xs.T\n",
    "\n",
    "\n",
    "\n",
    "# For training\n",
    "    # Perform non linear transforms\n",
    "    # Fit weights using linear regression (no constraints)\n",
    "    # Identify classification err on training\n",
    "# For testing\n",
    "    # Perform non linear transforms\n",
    "    # Apply weights\n",
    "    # Identify classification err on testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
